# mlFlow Registry QA & Prod pipeline 
trigger:
- master

pool:
  vmImage: 'ubuntu-latest'

steps:
- checkout: self
  persistCredentials: true
  clean: true
  displayName: 'Credentials'

- script: |
    pip install databricks-cli
    ~/.local/bin/databricks -h
  displayName: 'Install Databricks CLI'

- script: |
    pip install https://github.com/WeichenXu123/packages/raw/85911efdfca4a873314cefb44471cee9cb84e56b/mlflow/mlflow-job/mlflow-2.15.1.dev0-py3-none-any.whl
    ~/.local/bin/mlflow --version
  displayName: 'Install mlflow'

- script: |
    export MLFLOW_TRACKING_URI=databricks
    mlflow.set_experiment('mlflow-arg')
    mlflow run https://github.com/jjaiwant328/mlflow-arg  -b databricks --backend-config cluster-spec.json
  env:
    DATABRICKS_HOST: $(DATABRICKS_HOST)
    DATABRICKS_TOKEN: $(DATABRICKS_TOKEN)
  displayName: 'Run MLflow job test'


- script: |
    export MLFLOW_TRACKING_URI=databricks
    mlflow run https://github.com/jjaiwant328/jai-mlflow-job-test2  -b databricks --backend-config cluster-spec.json -P script_name=train.py -P model_name=sklearn --experiment-id 4480679818023526
  env:
    DATABRICKS_HOST: $(DATABRICKS_HOST)
    DATABRICKS_TOKEN: $(DATABRICKS_TOKEN)
    displayName: 'Run MLflow job test2'
